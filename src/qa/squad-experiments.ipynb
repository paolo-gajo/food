{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 130319\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 11873\n",
      "    })\n",
      "})\n",
      "{'input_ids': tensor([[  101,  2054, 11583,  ...,     0,     0,     0],\n",
      "        [  101,  1037,  2744,  ...,     0,     0,     0],\n",
      "        [  101,  2043,  2001,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2024,  1996,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  2003,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  2106,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "dataset = load_dataset(\"squad_v2\")\n",
    "# dataset['train'] = dataset['train'].select(range(32))\n",
    "# dataset['validation'] = dataset['validation'].select(range(32))\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['question'], examples['context'], padding = 'max_length', truncation = True)\n",
    "\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "dataset.set_format('torch', columns=['input_ids', 'token_type_ids', 'attention_mask'])\n",
    "print(dataset)\n",
    "\n",
    "train = torch.utils.data.DataLoader(dataset['train'], batch_size = 8, shuffle = True)\n",
    "val = torch.utils.data.DataLoader(dataset['validation'], batch_size = 8)\n",
    "\n",
    "for batch in train:\n",
    "    print(batch)\n",
    "    print(batch.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.modeling_bert.BertForQuestionAnswering'>\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "print(model.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in tqdm(enumerate(train), total = len(train)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
