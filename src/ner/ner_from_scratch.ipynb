{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pgajo/working/food/food-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification, BertTokenizerFast\n",
    "import torch\n",
    "torch.set_printoptions(linewidth=1000000)\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101,  8667,   117,  1139,  1271,  1110, 21283,  1105,   146,  1686,  1107,  3206,   102])\n",
      "13\n",
      "odict_keys(['logits', 'hidden_states', 'attentions'])\n",
      "tensor([[ 7.5478, -0.6597, -0.9438, -1.2462, -1.1459, -0.9863, -1.3880, -1.3161, -1.1247],\n",
      "        [ 9.6132, -1.2523, -2.7852, -0.3876, -2.3631, -0.8766, -2.2141, -0.6342, -1.6571],\n",
      "        [10.5307, -1.5881, -1.4932, -1.2315, -1.2756, -2.1707, -1.3378, -1.6861, -0.9634],\n",
      "        [10.3861, -1.4980, -1.9376, -0.9380, -1.5865, -2.1455, -1.5940, -1.4275, -1.0086],\n",
      "        [ 9.9562, -1.2993, -1.9742, -0.6742, -1.3692, -2.3556, -1.5589, -1.4247, -0.9545],\n",
      "        [ 9.9804, -1.2314, -1.8785, -0.8458, -1.5024, -2.4884, -1.4364, -1.4766, -0.7918],\n",
      "        [-0.6704, -1.1206, -2.9151,  7.4727, -1.8736,  0.3830, -2.6445,  0.3074, -2.0599],\n",
      "        [ 9.9543, -1.8136, -1.4337, -1.3405, -0.8808, -2.3044, -0.6465, -1.5741, -0.9902],\n",
      "        [10.0798, -1.6255, -2.4020, -0.4867, -1.6395, -2.0196, -1.7136, -0.9416, -1.2174],\n",
      "        [10.2258, -1.5564, -2.2185, -1.2296, -1.5871, -1.9818, -1.2967, -1.0923, -1.2562],\n",
      "        [10.3135, -1.0437, -2.3067, -1.1611, -2.0424, -1.9256, -1.5551, -0.8993, -1.1091],\n",
      "        [-0.5479, -0.9610, -2.1378, -0.7091, -2.0998, -0.4624, -1.5781,  8.8875, -1.3000],\n",
      "        [ 6.9153, -0.0617, -1.5531, -0.6474, -1.6872, -1.6228, -1.1598, -0.3037, -1.5352]], grad_fn=<SqueezeBackward0>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Hello, my name is Nico and I live in Berlin\"\n",
    "inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "print(inputs['input_ids'].squeeze())\n",
    "print(len(inputs['input_ids'].squeeze()))\n",
    "outputs = model(**inputs, output_hidden_states=True, output_attentions=True)\n",
    "print(outputs.keys())\n",
    "print(outputs.logits.squeeze())\n",
    "print(torch.argmax(outputs.logits.squeeze(), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'B-PER', 'score': 0.9990139, 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}\n",
      "{'entity': 'B-LOC', 'score': 0.999645, 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = \"My name is Wolfgang and I live in Berlin\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "for result in ner_results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
