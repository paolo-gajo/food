{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj7uA0qGZIHH"
      },
      "source": [
        "# NERfR (Named Entity Recognition for Recipes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysByC8eoUBWK"
      },
      "outputs": [],
      "source": [
        "# Installations and Imports\n",
        "import spacy\n",
        "import sys\n",
        "from tasteset_utils import prepare_data, ENTITIES\n",
        "import json\n",
        "# json_path = '/home/pgajo/working/food/data/TASTEset/data/TASTEset_semicolon_formatted_en-it_unaligned_aligned_model=mdeberta-v3-base-xl-wa_recipe_aligner_5epochs_error_rate=0.0119_pruned.json'\n",
        "json_path = '/home/pgajo/working/food/data/TASTEset/data/TASTEset_semicolon_formatted_en-it_itemwise.json'\n",
        "\n",
        "with open(json_path, 'r') as f:\n",
        "    training_data = json.load(f)\n",
        "print(training_data['annotations'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2UHaCcw_cKi"
      },
      "outputs": [],
      "source": [
        "# make spacy dataset from tasteset format\n",
        "from spacy.tokens import DocBin\n",
        "import os\n",
        "import re\n",
        "\n",
        "def tasteset_to_spacy_formatter(training_annotations, languages = ['en']):\n",
        "  num_of_entities = 0\n",
        "  doc_bin = DocBin()\n",
        "  for lang in languages:\n",
        "    nlp = spacy.blank(lang)\n",
        "    for idx, example in enumerate(training_annotations):\n",
        "      doc = nlp.make_doc(re.sub(r'-(\\d+)', r' \\1', example[f'text_{lang}'].replace(';', ' ')))\n",
        "      print(idx, 'doc:', doc)\n",
        "      ents = []\n",
        "      # print(\"len(example[f'ents_{lang}']):\", len(example[f'ents_{lang}']))\n",
        "      for i, entity in enumerate(example[f'ents_{lang}']):\n",
        "        span = doc.char_span(*entity, alignment_mode='strict')\n",
        "        # print('span.start', span.start)\n",
        "        # print('span.end', span.end)\n",
        "        # print(i, 'entity\\t', entity, '\\tspan:\\t', span)\n",
        "        # print(i, 'entity\\t', entity, '\\traw:\\t', example[f'text_{lang}'][entity[0]:entity[1]])\n",
        "        # if the span is None, skip it and don't add it to the doc's entities\n",
        "        if span is None:\n",
        "          continue\n",
        "        ents.append(span)\n",
        "        num_of_entities += 1\n",
        "      \n",
        "      doc.ents = ents\n",
        "      doc_bin.add(doc)\n",
        "    \n",
        "  print('num_of_entities:', num_of_entities)\n",
        "  return doc_bin\n",
        "\n",
        "train_len = int(0.8*len(training_data['annotations'])) # 80/20 split\n",
        "languages = ['it']\n",
        "lang_id = '-'.join(languages)\n",
        "train_bin = tasteset_to_spacy_formatter(training_data['annotations'][:train_len], languages = languages)\n",
        "print('train_bin length:', len(train_bin))\n",
        "dev_bin = tasteset_to_spacy_formatter(training_data['annotations'][train_len:], languages = languages)\n",
        "print('dev_bin length:', len(dev_bin))\n",
        "spacy_dir = '/home/pgajo/working/food/data/TASTEset/data/spacy'\n",
        "train_path = os.path.join(spacy_dir, f\"{lang_id}_train.spacy\")\n",
        "dev_path = os.path.join(spacy_dir, f\"{lang_id}_dev.spacy\")\n",
        "train_bin.to_disk(train_path)\n",
        "dev_bin.to_disk(dev_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformer config\n",
        "model_name = 'bert-base-multilingual-cased'\n",
        "BASE_CONFIG_TRANFORMER = \"\"\"\n",
        "# This is an auto-generated partial config. To use it with 'spacy train'\n",
        "# you can run spacy init fill-config to auto-fill all default settings:\n",
        "# python -m spacy init fill-config ./base_config.cfg ./config.cfg\n",
        "[paths]\n",
        "train = train_path\n",
        "dev = dev_path\n",
        "vectors = null\n",
        "[system]\n",
        "gpu_allocator = \"pytorch\"\n",
        "\n",
        "[nlp]\n",
        "lang = \"it\"\n",
        "pipeline = [\"transformer\",\"ner\"]\n",
        "batch_size = 128\n",
        "\n",
        "[components]\n",
        "\n",
        "[components.transformer]\n",
        "factory = \"transformer\"\n",
        "\n",
        "[components.transformer.model]\n",
        "@architectures = \"spacy-transformers.TransformerModel.v3\"\n",
        "name = \"model_name\"\n",
        "# name = \"microsoft/mdeberta-v3-base\"\n",
        "tokenizer_config = {\"use_fast\": true}\n",
        "\n",
        "[components.transformer.model.get_spans]\n",
        "@span_getters = \"spacy-transformers.strided_spans.v1\"\n",
        "window = 128\n",
        "stride = 96\n",
        "\n",
        "[components.ner]\n",
        "factory = \"ner\"\n",
        "\n",
        "[components.ner.model]\n",
        "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
        "state_type = \"ner\"\n",
        "extra_state_tokens = false\n",
        "hidden_width = 64\n",
        "maxout_pieces = 2\n",
        "use_upper = false\n",
        "nO = null\n",
        "\n",
        "[components.ner.model.tok2vec]\n",
        "@architectures = \"spacy-transformers.TransformerListener.v1\"\n",
        "grad_factor = 1.0\n",
        "\n",
        "[components.ner.model.tok2vec.pooling]\n",
        "@layers = \"reduce_mean.v1\"\n",
        "\n",
        "[corpora]\n",
        "\n",
        "[corpora.train]\n",
        "@readers = \"spacy.Corpus.v1\"\n",
        "path = ${paths.train}\n",
        "max_length = 0\n",
        "\n",
        "[corpora.dev]\n",
        "@readers = \"spacy.Corpus.v1\"\n",
        "path = ${paths.dev}\n",
        "max_length = 0\n",
        "\n",
        "[training]\n",
        "accumulate_gradient = 3\n",
        "dev_corpus = \"corpora.dev\"\n",
        "train_corpus = \"corpora.train\"\n",
        "\n",
        "[training.optimizer]\n",
        "@optimizers = \"Adam.v1\"\n",
        "\n",
        "[training.optimizer.learn_rate]\n",
        "@schedules = \"warmup_linear.v1\"\n",
        "warmup_steps = 250\n",
        "total_steps = 5000\n",
        "initial_rate = 2e-5\n",
        "\n",
        "[training.batcher]\n",
        "@batchers = \"spacy.batch_by_padded.v1\"\n",
        "discard_oversize = true\n",
        "size = 2000\n",
        "buffer = 256\n",
        "\n",
        "[initialize]\n",
        "vectors = ${paths.vectors}\"\"\"\n",
        "BASE_CONFIG_TRANFORMER = BASE_CONFIG_TRANFORMER.replace('model_name', model_name)\n",
        "BASE_CONFIG_TRANFORMER = BASE_CONFIG_TRANFORMER.replace('train_path', train_path)\n",
        "BASE_CONFIG_TRANFORMER = BASE_CONFIG_TRANFORMER.replace('dev_path', dev_path)\n",
        "print(BASE_CONFIG_TRANFORMER)\n",
        "base_config_path = f\"{model_name}.cfg\"\n",
        "with open(base_config_path, 'w') as f:\n",
        "  f.write(BASE_CONFIG_TRANFORMER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7HSLGd-Bx0e",
        "outputId": "c1dbe6a9-c220-427b-a19a-00529ab83310"
      },
      "outputs": [],
      "source": [
        "# This command fills in your config with from the base_config you generated. The\n",
        "# last argument is the name of your config. I used \"_eff\" for \"efficiency\". Feel\n",
        "# free to change that\n",
        "# !python -m spacy init fill-config mbert.cfg config_mbert.cfg\n",
        "model_config_path = f\"config_{model_name}.cfg\"\n",
        "!python -m spacy init fill-config \"$base_config_path\" \"$model_config_path\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcdUi-uag79A"
      },
      "source": [
        "## Training\n",
        "\n",
        "Run the following code to train! Note that you'll have to change the path and name of the `.cfg` file as necessary. The last argument is a folder that'll contain your pipeline. Feel free to prefix it with a path to a more useful location. Also have some fun with the name!\n",
        "\n",
        "You'll get periodic updates with the `loss`, `F1`, `precision`, `recall` for the NER model over time. They also give you a `SCORE`, which is helpful when training multiple components, but in our case, the `SCORE` is just the `F1` score for the NER model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGK-9GucDUqQ",
        "outputId": "3c341506-f3ef-4b69-f8db-084b79bcdd4a"
      },
      "outputs": [],
      "source": [
        "suffix = 'item-wise'\n",
        "output_path = f\"output_{model_name}_{lang_id}_{suffix}\"\n",
        "!python -m spacy train \"$model_config_path\" --output \"$output_path\" -g 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp9fYB6CfZQR"
      },
      "source": [
        "## Results\n",
        "\n",
        "The training outputs a `meta.json` file in the output folder (`output_eff` in our case). We can use this to check a number of metrics, including the performance of each entity class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PckfQRDo4o8S"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# grab the performance dict from within the meta file\n",
        "print(f\"{output_path}/model-best/meta.json\")\n",
        "performance = json.load(open(f\"{output_path}/model-best/meta.json\", 'r'))['performance']\n",
        "performance_by_ent = performance['ents_per_type']\n",
        "\n",
        "perf_df = pd.DataFrame(performance_by_ent)\n",
        "perf_df[\"TOTAL\"] = [performance['ents_p'], performance['ents_r'], performance['ents_f']]\n",
        "# sort by header\n",
        "perf_df = perf_df.reindex(sorted(perf_df.columns), axis=1)\n",
        "\n",
        "# display df with the cell color corresponding to the value (dark=high; light=low)\n",
        "perf_df.style.background_gradient(\n",
        "    axis=1, low=perf_df.min().min(), high=1, cmap='YlOrBr'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lqB7YOzknk3"
      },
      "source": [
        "Here we've got the precision (p), recall (r), and F1 (f) score by entity. It seems like the best performing entities are the ones we care the most about. Only 40% of *PART* entities are being turned up. I can live with that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHzHar66xZG5"
      },
      "source": [
        "## Getting the Confusion Matrix\n",
        "\n",
        "We're going to be plotting a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) on the same test set we used for training. At a high level, this entails running each sample through the trained model, and, for each token, storing the entity the model predicted for that token, as well as the ground truth entity (as labeled by the dataset authors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrIleK5oxrHu"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "# load the model and test set. Again, change the paths as required\n",
        "nlp = spacy.load(f\"{output_path}/model-best\")\n",
        "test_set = list(DocBin().from_disk(dev_path).get_docs(nlp.vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glbxDfxJB4h0"
      },
      "outputs": [],
      "source": [
        "pred_ents = []\n",
        "true_ents = []\n",
        "\n",
        "for recipe in test_set:\n",
        "  # tok.ent_type_ gets the ent per token, as opposed to breaking the Doc into\n",
        "  # entities. This ensures that `true_ents` and `pred_ents` are the same length.\n",
        "  true_ents += [tok.ent_type_ for tok in recipe]\n",
        "  # `recipe.text` grabs the raw recipe, because `recipe` already contains entity\n",
        "  # labels.\n",
        "  pred_ents += [tok.ent_type_ for tok in nlp(recipe.text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "DChFnKdSGqwV",
        "outputId": "4cab256d-9bb4-4811-f9f7-acd0e6ef856e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# create and display the confusion matrix\n",
        "cm = confusion_matrix(true_ents, pred_ents, labels=ENTITIES)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ENTITIES)\n",
        "\n",
        "disp.plot()\n",
        "plt.xticks(rotation=70)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRNNbNy9-F7o"
      },
      "source": [
        "Unfortunately, there isn't quite enough data for the color mapping to show fine-grained differences. Nonetheless, we can get a sense for the more common mislabelings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pgajo/working/food/food-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_of_entities: 20319\n",
            "test_bin length: 597\n",
            "/home/pgajo/working/food/data/TASTEset/data/spacy/it_gz-recipes-annotated.json_test.spacy\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import spacy\n",
        "import os\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "\n",
        "# make spacy dataset from label-studio format\n",
        "\n",
        "def label_studio_to_spacy_formatter(label_studio_json_data, languages = ['en']):\n",
        "  num_of_entities = 0\n",
        "  doc_bin = DocBin()\n",
        "  for lang in languages:\n",
        "    nlp = spacy.blank(lang)\n",
        "    for idx, example in enumerate(label_studio_json_data):\n",
        "      text = example['data']['ingredients_it']\n",
        "      doc = nlp.make_doc(text.replace(';', ' '))\n",
        "      # print(idx, 'doc:', doc)\n",
        "      ents = []\n",
        "      for i, entity_ls in enumerate(example['annotations'][0]['result']):\n",
        "        entity = [entity_ls['value']['start'],\n",
        "                    entity_ls['value']['end'],\n",
        "                    entity_ls['value']['labels'][0]]\n",
        "        span = doc.char_span(*entity,\n",
        "                            alignment_mode='strict')\n",
        "\n",
        "        if span is None:\n",
        "          print('********************')\n",
        "          print(idx, entity, text[entity[0]:entity[1]])\n",
        "          continue\n",
        "        ents.append(span)\n",
        "        num_of_entities += 1\n",
        "      \n",
        "      try:\n",
        "        doc.ents = ents\n",
        "      except Exception as e:\n",
        "        print(idx, 'doc:', doc)\n",
        "        print(\"error:\", e)\n",
        "        # sort entities by start and retain None by making it a dummy entry \n",
        "        # ents = sorted([ent for ent in ents if ent is not None], key=lambda x: x.start)\n",
        "        for ent in ents:\n",
        "            if ent is not None:\n",
        "                print(ent.start, ent.end, ent.label_, ent.text)\n",
        "            else:\n",
        "                print(ent)\n",
        "        print('-------------------')\n",
        "      doc_bin.add(doc)\n",
        "    \n",
        "  print('num_of_entities:', num_of_entities)\n",
        "  return doc_bin\n",
        "\n",
        "test_json_path = '/home/pgajo/working/food/data/GZ/gz-recipes-annotated/gz-recipes-annotated.json'\n",
        "\n",
        "with open(test_json_path, 'r') as f:\n",
        "    test_json = json.load(f)\n",
        "\n",
        "test_len = int(0.8*len(test_json)) # 80/20 split\n",
        "languages = ['it']\n",
        "lang_id = '-'.join(languages)\n",
        "test_bin = label_studio_to_spacy_formatter(test_json, languages = languages)\n",
        "print('test_bin length:', len(test_bin))\n",
        "\n",
        "spacy_dir = '/home/pgajo/working/food/data/TASTEset/data/spacy'\n",
        "test_path = os.path.join(spacy_dir, f\"{lang_id}_{os.path.basename(test_json_path)}_test.spacy\")\n",
        "print(test_path)\n",
        "test_bin.to_disk(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 597/597 [00:22<00:00, 26.90it/s]\n",
            "/home/pgajo/working/food/food-env/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>COLOR</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.006342</td>\n",
              "      <td>0.012579</td>\n",
              "      <td>473.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOOD</th>\n",
              "      <td>0.577471</td>\n",
              "      <td>0.582290</td>\n",
              "      <td>0.579871</td>\n",
              "      <td>6471.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PART</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.007576</td>\n",
              "      <td>0.014493</td>\n",
              "      <td>264.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PHYSICAL_QUALITY</th>\n",
              "      <td>0.497925</td>\n",
              "      <td>0.074906</td>\n",
              "      <td>0.130222</td>\n",
              "      <td>1602.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PROCESS</th>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.119342</td>\n",
              "      <td>0.162921</td>\n",
              "      <td>243.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PURPOSE</th>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QUALITY/BRAND</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QUANTITY</th>\n",
              "      <td>0.878615</td>\n",
              "      <td>0.750305</td>\n",
              "      <td>0.809406</td>\n",
              "      <td>6560.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TASTE</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UNIT</th>\n",
              "      <td>0.977576</td>\n",
              "      <td>0.974266</td>\n",
              "      <td>0.975919</td>\n",
              "      <td>4430.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro avg</th>\n",
              "      <td>0.777327</td>\n",
              "      <td>0.650623</td>\n",
              "      <td>0.708353</td>\n",
              "      <td>20319.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.478671</td>\n",
              "      <td>0.294360</td>\n",
              "      <td>0.321173</td>\n",
              "      <td>20319.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.747352</td>\n",
              "      <td>0.650623</td>\n",
              "      <td>0.675084</td>\n",
              "      <td>20319.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  precision    recall  f1-score  support\n",
              "COLOR              0.750000  0.006342  0.012579    473.0\n",
              "FOOD               0.577471  0.582290  0.579871   6471.0\n",
              "PART               0.166667  0.007576  0.014493    264.0\n",
              "PHYSICAL_QUALITY   0.497925  0.074906  0.130222   1602.0\n",
              "PROCESS            0.256637  0.119342  0.162921    243.0\n",
              "PURPOSE            0.681818  0.428571  0.526316    140.0\n",
              "QUALITY/BRAND      0.000000  0.000000  0.000000     70.0\n",
              "QUANTITY           0.878615  0.750305  0.809406   6560.0\n",
              "TASTE              0.000000  0.000000  0.000000     66.0\n",
              "UNIT               0.977576  0.974266  0.975919   4430.0\n",
              "micro avg          0.777327  0.650623  0.708353  20319.0\n",
              "macro avg          0.478671  0.294360  0.321173  20319.0\n",
              "weighted avg       0.747352  0.650623  0.675084  20319.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 597/597 [00:21<00:00, 27.21it/s]\n",
            "/home/pgajo/working/food/food-env/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>COLOR</th>\n",
              "      <td>0.910064</td>\n",
              "      <td>0.898520</td>\n",
              "      <td>0.904255</td>\n",
              "      <td>473.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FOOD</th>\n",
              "      <td>0.693579</td>\n",
              "      <td>0.667748</td>\n",
              "      <td>0.680419</td>\n",
              "      <td>6471.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PART</th>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.003788</td>\n",
              "      <td>0.007117</td>\n",
              "      <td>264.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PHYSICAL_QUALITY</th>\n",
              "      <td>0.586503</td>\n",
              "      <td>0.298377</td>\n",
              "      <td>0.395532</td>\n",
              "      <td>1602.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PROCESS</th>\n",
              "      <td>0.232673</td>\n",
              "      <td>0.193416</td>\n",
              "      <td>0.211236</td>\n",
              "      <td>243.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PURPOSE</th>\n",
              "      <td>0.388060</td>\n",
              "      <td>0.185714</td>\n",
              "      <td>0.251208</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QUALITY/BRAND</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QUANTITY</th>\n",
              "      <td>0.948100</td>\n",
              "      <td>0.821494</td>\n",
              "      <td>0.880268</td>\n",
              "      <td>6560.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TASTE</th>\n",
              "      <td>0.457143</td>\n",
              "      <td>0.242424</td>\n",
              "      <td>0.316832</td>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UNIT</th>\n",
              "      <td>0.932135</td>\n",
              "      <td>0.936343</td>\n",
              "      <td>0.934234</td>\n",
              "      <td>4430.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>micro avg</th>\n",
              "      <td>0.826571</td>\n",
              "      <td>0.730892</td>\n",
              "      <td>0.775793</td>\n",
              "      <td>20319.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.520708</td>\n",
              "      <td>0.424782</td>\n",
              "      <td>0.458110</td>\n",
              "      <td>20319.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.805337</td>\n",
              "      <td>0.730892</td>\n",
              "      <td>0.762186</td>\n",
              "      <td>20319.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  precision    recall  f1-score  support\n",
              "COLOR              0.910064  0.898520  0.904255    473.0\n",
              "FOOD               0.693579  0.667748  0.680419   6471.0\n",
              "PART               0.058824  0.003788  0.007117    264.0\n",
              "PHYSICAL_QUALITY   0.586503  0.298377  0.395532   1602.0\n",
              "PROCESS            0.232673  0.193416  0.211236    243.0\n",
              "PURPOSE            0.388060  0.185714  0.251208    140.0\n",
              "QUALITY/BRAND      0.000000  0.000000  0.000000     70.0\n",
              "QUANTITY           0.948100  0.821494  0.880268   6560.0\n",
              "TASTE              0.457143  0.242424  0.316832     66.0\n",
              "UNIT               0.932135  0.936343  0.934234   4430.0\n",
              "micro avg          0.826571  0.730892  0.775793  20319.0\n",
              "macro avg          0.520708  0.424782  0.458110  20319.0\n",
              "weighted avg       0.805337  0.730892  0.762186  20319.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# metrics using seqeval\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "model_path_1 = '/home/pgajo/working/food/src/ner/spacy_outputs/output_bert-base-multilingual-cased_it_item-wise/model-best'\n",
        "model_path_2 = '/home/pgajo/working/food/src/ner/spacy_outputs/output_bert-base-multilingual-cased_it/model-best'\n",
        "\n",
        "model_path_list = [model_path_1, model_path_2]\n",
        "stats = []\n",
        "\n",
        "import spacy\n",
        "ENTITIES = [el.strip() for el in open('/home/pgajo/working/food/data/TASTEset/data/classes').readlines()]\n",
        "# print(ENTITIES)\n",
        "\n",
        "for model_path in model_path_list:\n",
        "\n",
        "    nlp = spacy.load(model_path)\n",
        "    test_set = list(DocBin().from_disk(test_path).get_docs(nlp.vocab))\n",
        "    # test_set = test_set[:2]\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for doc in tqdm(test_set, total = len(test_set)):\n",
        "        y_true_sample = []\n",
        "        for tok in doc:\n",
        "            if tok.ent_type_ != '':\n",
        "                y_true_sample.append('-'.join([tok.ent_iob_, tok.ent_type_]))\n",
        "            elif tok.ent_type_ == '':\n",
        "                y_true_sample.append(tok.ent_iob_)\n",
        "\n",
        "        y_true.append(y_true_sample)\n",
        "\n",
        "        y_pred_sample = []\n",
        "        for tok in nlp(doc.text):\n",
        "            if tok.ent_type_ != '':\n",
        "                y_pred_sample.append('-'.join([tok.ent_iob_, tok.ent_type_]))\n",
        "            elif tok.ent_type_ == '':\n",
        "                y_pred_sample.append(tok.ent_iob_)\n",
        "        \n",
        "        y_pred.append(y_pred_sample)\n",
        "\n",
        "    results_seqeval = classification_report(y_true, y_pred, output_dict=True)\n",
        "    df_results_seqeval = pd.DataFrame(results_seqeval).T\n",
        "    display(df_results_seqeval)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_seqeval.__class__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['FOOD', 'QUANTITY', 'UNIT', 'PROCESS', 'PHYSICAL_QUALITY', 'COLOR', 'TASTE', 'PURPOSE', 'PART']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 597/597 [00:21<00:00, 27.34it/s]\n",
            "100%|██████████| 597/597 [00:22<00:00, 27.03it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entity</th>\n",
              "      <th>model</th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>macro</td>\n",
              "      <td>output_bert-base-multilingual-cased_it_item-wise</td>\n",
              "      <td>0.531857</td>\n",
              "      <td>0.327067</td>\n",
              "      <td>0.356859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>micro</td>\n",
              "      <td>output_bert-base-multilingual-cased_it_item-wise</td>\n",
              "      <td>0.777327</td>\n",
              "      <td>0.652872</td>\n",
              "      <td>0.709684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FOOD</td>\n",
              "      <td>output_bert-base-multilingual-cased_it_item-wise</td>\n",
              "      <td>0.577471</td>\n",
              "      <td>0.582290</td>\n",
              "      <td>0.579871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>QUANTITY</td>\n",
              "      <td>output_bert-base-multilingual-cased_it_item-wise</td>\n",
              "      <td>0.878615</td>\n",
              "      <td>0.750305</td>\n",
              "      <td>0.809406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>UNIT</td>\n",
              "      <td>output_bert-base-multilingual-cased_it_item-wise</td>\n",
              "      <td>0.977576</td>\n",
              "      <td>0.974266</td>\n",
              "      <td>0.975919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PHYSICAL_QUALITY</td>\n",
              "      <td>output_bert-base-multilingual-cased_it_item-wise</td>\n",
              "      <td>0.497925</td>\n",
              "      <td>0.074906</td>\n",
              "      <td>0.130222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TASTE</td>\n",
              "      <td>output_bert-base-multilingual-cased_it_item-wise</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PART</td>\n",
              "      <td>output_bert-base-multilingual-cased_it_item-wise</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.007576</td>\n",
              "      <td>0.014493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>PURPOSE</td>\n",
              "      <td>output_bert-base-multilingual-cased_it_item-wise</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>COLOR</td>\n",
              "      <td>output_bert-base-multilingual-cased_it_item-wise</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.006342</td>\n",
              "      <td>0.012579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>PROCESS</td>\n",
              "      <td>output_bert-base-multilingual-cased_it_item-wise</td>\n",
              "      <td>0.256637</td>\n",
              "      <td>0.119342</td>\n",
              "      <td>0.162921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>macro</td>\n",
              "      <td>output_bert-base-multilingual-cased_it</td>\n",
              "      <td>0.578565</td>\n",
              "      <td>0.471981</td>\n",
              "      <td>0.509011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>micro</td>\n",
              "      <td>output_bert-base-multilingual-cased_it</td>\n",
              "      <td>0.826571</td>\n",
              "      <td>0.733419</td>\n",
              "      <td>0.777214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>FOOD</td>\n",
              "      <td>output_bert-base-multilingual-cased_it</td>\n",
              "      <td>0.693579</td>\n",
              "      <td>0.667748</td>\n",
              "      <td>0.680419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>QUANTITY</td>\n",
              "      <td>output_bert-base-multilingual-cased_it</td>\n",
              "      <td>0.948100</td>\n",
              "      <td>0.821494</td>\n",
              "      <td>0.880268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>PHYSICAL_QUALITY</td>\n",
              "      <td>output_bert-base-multilingual-cased_it</td>\n",
              "      <td>0.586503</td>\n",
              "      <td>0.298377</td>\n",
              "      <td>0.395532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>UNIT</td>\n",
              "      <td>output_bert-base-multilingual-cased_it</td>\n",
              "      <td>0.932135</td>\n",
              "      <td>0.936343</td>\n",
              "      <td>0.934234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>TASTE</td>\n",
              "      <td>output_bert-base-multilingual-cased_it</td>\n",
              "      <td>0.457143</td>\n",
              "      <td>0.242424</td>\n",
              "      <td>0.316832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>PART</td>\n",
              "      <td>output_bert-base-multilingual-cased_it</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.003788</td>\n",
              "      <td>0.007117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>PROCESS</td>\n",
              "      <td>output_bert-base-multilingual-cased_it</td>\n",
              "      <td>0.232673</td>\n",
              "      <td>0.193416</td>\n",
              "      <td>0.211236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>PURPOSE</td>\n",
              "      <td>output_bert-base-multilingual-cased_it</td>\n",
              "      <td>0.388060</td>\n",
              "      <td>0.185714</td>\n",
              "      <td>0.251208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>COLOR</td>\n",
              "      <td>output_bert-base-multilingual-cased_it</td>\n",
              "      <td>0.910064</td>\n",
              "      <td>0.898520</td>\n",
              "      <td>0.904255</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              entity                                             model  \\\n",
              "0              macro  output_bert-base-multilingual-cased_it_item-wise   \n",
              "1              micro  output_bert-base-multilingual-cased_it_item-wise   \n",
              "2               FOOD  output_bert-base-multilingual-cased_it_item-wise   \n",
              "3           QUANTITY  output_bert-base-multilingual-cased_it_item-wise   \n",
              "4               UNIT  output_bert-base-multilingual-cased_it_item-wise   \n",
              "5   PHYSICAL_QUALITY  output_bert-base-multilingual-cased_it_item-wise   \n",
              "6              TASTE  output_bert-base-multilingual-cased_it_item-wise   \n",
              "7               PART  output_bert-base-multilingual-cased_it_item-wise   \n",
              "8            PURPOSE  output_bert-base-multilingual-cased_it_item-wise   \n",
              "9              COLOR  output_bert-base-multilingual-cased_it_item-wise   \n",
              "10           PROCESS  output_bert-base-multilingual-cased_it_item-wise   \n",
              "11             macro            output_bert-base-multilingual-cased_it   \n",
              "12             micro            output_bert-base-multilingual-cased_it   \n",
              "13              FOOD            output_bert-base-multilingual-cased_it   \n",
              "14          QUANTITY            output_bert-base-multilingual-cased_it   \n",
              "15  PHYSICAL_QUALITY            output_bert-base-multilingual-cased_it   \n",
              "16              UNIT            output_bert-base-multilingual-cased_it   \n",
              "17             TASTE            output_bert-base-multilingual-cased_it   \n",
              "18              PART            output_bert-base-multilingual-cased_it   \n",
              "19           PROCESS            output_bert-base-multilingual-cased_it   \n",
              "20           PURPOSE            output_bert-base-multilingual-cased_it   \n",
              "21             COLOR            output_bert-base-multilingual-cased_it   \n",
              "\n",
              "           p         r        f1  \n",
              "0   0.531857  0.327067  0.356859  \n",
              "1   0.777327  0.652872  0.709684  \n",
              "2   0.577471  0.582290  0.579871  \n",
              "3   0.878615  0.750305  0.809406  \n",
              "4   0.977576  0.974266  0.975919  \n",
              "5   0.497925  0.074906  0.130222  \n",
              "6   0.000000  0.000000  0.000000  \n",
              "7   0.166667  0.007576  0.014493  \n",
              "8   0.681818  0.428571  0.526316  \n",
              "9   0.750000  0.006342  0.012579  \n",
              "10  0.256637  0.119342  0.162921  \n",
              "11  0.578565  0.471981  0.509011  \n",
              "12  0.826571  0.733419  0.777214  \n",
              "13  0.693579  0.667748  0.680419  \n",
              "14  0.948100  0.821494  0.880268  \n",
              "15  0.586503  0.298377  0.395532  \n",
              "16  0.932135  0.936343  0.934234  \n",
              "17  0.457143  0.242424  0.316832  \n",
              "18  0.058824  0.003788  0.007117  \n",
              "19  0.232673  0.193416  0.211236  \n",
              "20  0.388060  0.185714  0.251208  \n",
              "21  0.910064  0.898520  0.904255  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# metrics using spacy scorer\n",
        "from spacy.training import Example\n",
        "from spacy.scorer import get_ner_prf\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "model_path_1 = '/home/pgajo/working/food/src/ner/spacy_outputs/output_bert-base-multilingual-cased_it_item-wise/model-best'\n",
        "model_path_2 = '/home/pgajo/working/food/src/ner/spacy_outputs/output_bert-base-multilingual-cased_it/model-best'\n",
        "\n",
        "model_path_list = [model_path_1, model_path_2]\n",
        "stats = []\n",
        "\n",
        "import spacy\n",
        "ENTITIES = [el.strip() for el in open('/home/pgajo/working/food/data/TASTEset/data/classes').readlines()]\n",
        "# print(ENTITIES)\n",
        "\n",
        "for model_path in model_path_list:\n",
        "\n",
        "    nlp = spacy.load(model_path)\n",
        "    test_set = list(DocBin().from_disk(test_path).get_docs(nlp.vocab))\n",
        "    # test_set = test_set[:2]\n",
        "    examples = []\n",
        "    for doc in tqdm(test_set, total = len(test_set)):\n",
        "        ents = doc.ents\n",
        "        golds = [(ent.start_char, ent.end_char, ent.label_) for ent in ents if ent.label_ in ENTITIES]\n",
        "        preds = nlp(doc.text)\n",
        "        gold_dict = {'entities': golds}\n",
        "        example = Example.from_dict(preds, gold_dict)\n",
        "        examples.append(example)\n",
        "    results = get_ner_prf(examples)\n",
        "    # print(results['ents_f'])\n",
        "\n",
        "    model_name = model_path.split('/')[-2]\n",
        "    # print(model_name)\n",
        "\n",
        "    per_entity_stats = []\n",
        "    prec_sum = 0\n",
        "    rec_sum = 0\n",
        "    f1_sum = 0\n",
        "    for key in results['ents_per_type'].keys():\n",
        "        per_entity_stats.append([key, model_name, results['ents_per_type'][key]['p'], results['ents_per_type'][key]['r'], results['ents_per_type'][key]['f']])\n",
        "        prec_sum += results['ents_per_type'][key]['p']\n",
        "        rec_sum += results['ents_per_type'][key]['r']\n",
        "        f1_sum += results['ents_per_type'][key]['f']\n",
        "\n",
        "    macro_prec = prec_sum / len(per_entity_stats)\n",
        "    macro_rec = rec_sum / len(per_entity_stats)\n",
        "    macro_f1 = f1_sum / len(per_entity_stats)\n",
        "\n",
        "    macro_stats_row = ['macro', model_name, macro_prec, macro_rec, macro_f1]\n",
        "    stats.append(macro_stats_row)\n",
        "\n",
        "    micro_stats_row = ['micro', model_name, results['ents_p'], results['ents_r'], results['ents_f']]\n",
        "    stats.append(micro_stats_row)\n",
        "\n",
        "    stats += per_entity_stats \n",
        "\n",
        "# print(stats)\n",
        "df_results = pd.DataFrame(stats, columns=['entity', 'model', 'p', 'r', 'f1'])\n",
        "display(df_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results.to_csv('/home/pgajo/working/food/src/ner/metrics/multilingual_ner_results.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(test_set[0].ents)\n",
        "print(len(test_set[0].ents))\n",
        "print(len(test_set[0]))\n",
        "\n",
        "print(test_set[0][0])\n",
        "print(dir(test_set[0][0]))\n",
        "print(test_set[0][0].__class__)\n",
        "print(test_set[0][0].ent_iob_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report # this doesn't work with classification report, gotta look into how to actually compute metrics for NER\n",
        "\n",
        "true_ents = []\n",
        "pred_ents = []\n",
        "test_set = test_set[:3]\n",
        "for item in tqdm(test_set, total = len(test_set)):\n",
        "    # true_ents.append([tok.ent_type_ for tok in item])\n",
        "    # pred_ents.append([tok.ent_type_ for tok in nlp(item.text)])\n",
        "    print([tok.ent_type_ for tok in item])\n",
        "    print([tok.ent_type_ for tok in nlp(item.text)])\n",
        "\n",
        "# classification_report(true_ents, pred_ents, labels=ENTITIES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make confusion matrix\n",
        "pred_ents = []\n",
        "true_ents = []\n",
        "\n",
        "for recipe in tqdm(test_set, total=len(test_set)):\n",
        "  # tok.ent_type_ gets the ent per token, as opposed to breaking the Doc into\n",
        "  # entities. This ensures that `true_ents` and `pred_ents` are the same length.\n",
        "  true_ents += [tok.ent_type_ for tok in recipe]\n",
        "  # `recipe.text` grabs the raw recipe, because `recipe` already contains entity\n",
        "  # labels.\n",
        "  pred_ents += [tok.ent_type_ for tok in nlp(recipe.text)]\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tasteset_utils import ENTITIES\n",
        "\n",
        "# create and display the confusion matrix\n",
        "cm = confusion_matrix(true_ents, pred_ents, labels=ENTITIES)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ENTITIES)\n",
        "\n",
        "disp.plot()\n",
        "plt.xticks(rotation=70)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation metrics\n",
        "import spacy \n",
        "from spacy.tokens import Span\n",
        "from spacy import displacy\n",
        "from spacy.training import *\n",
        "from spacy.scorer import Scorer\n",
        "from spacy.util import minibatch, compounding\n",
        "from tqdm import tqdm\n",
        "\n",
        "model_paths = ['/home/pgajo/working/food/src/ner/spacy_outputs/output_bert-base-multilingual-cased_it_item-wise/model-best',\n",
        "'/home/pgajo/working/food/src/ner/spacy_outputs/output_bert-base-multilingual-cased_it/model-best']\n",
        "\n",
        "results = []\n",
        "\n",
        "for i, model_path in enumerate(model_paths):\n",
        "    nlp = spacy.load(model_path)\n",
        "    test_data = list(test_bin.get_docs(nlp.vocab))\n",
        "\n",
        "    # evaluate function\n",
        "    def evaluate(ner_model, testing_data):\n",
        "        scorer = Scorer()\n",
        "        examples = []\n",
        "        for sample in tqdm(testing_data, desc=\"Evaluating\", total=len(testing_data)):\n",
        "            doc_gold_text = ner_model.make_doc(sample.text)\n",
        "            example = Example.from_dict(doc_gold_text, {\"entities\": [(ent.start_char, ent.end_char, ent.label_) for ent in sample.ents if ent.label_ in ENTITIES]})\n",
        "            print('1', example.__class__)\n",
        "            print('1', example)\n",
        "            example.predicted = ner_model(doc_gold_text)\n",
        "            print('2', example.predicted.__class__)\n",
        "            print('2', example.predicted)\n",
        "            for tok in example.predicted:\n",
        "                print(tok.ent_type_)\n",
        "            examples.append(example)\n",
        "            print('*************')\n",
        "            \n",
        "        return scorer.score(examples)\n",
        "\n",
        "    # print the results\n",
        "    results.append(evaluate(nlp, test_data[:1]))\n",
        "    print(i, results[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stats = []\n",
        "for i, result in enumerate(results):\n",
        "    model_stats = []\n",
        "    overall_stats = [model_paths[i].split('/')[-2], 'macro', result['ents_p'], result['ents_r'], result['ents_f']]\n",
        "    model_stats.append(overall_stats)\n",
        "    for ent in result['ents_per_type'].keys():\n",
        "        ent_stats = [model_paths[i].split('/')[-2], ent, result['ents_per_type'][ent]['p'], result['ents_per_type'][ent]['r'], result['ents_per_type'][ent]['f']]\n",
        "        model_stats.append(ent_stats)\n",
        "    stats.append(model_stats)\n",
        "for el in stats:\n",
        "    print(el)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "metrics_dir = '/home/pgajo/working/food/src/ner/metrics'\n",
        "\n",
        "dataframes = []\n",
        "for i, stat in enumerate(stats):\n",
        "    df = pd.DataFrame(stat, columns=['model', 'entity', 'precision', 'recall', 'f-score'])\n",
        "    dataframes.append(df)\n",
        "    display(df)\n",
        "    df.to_csv(os.path.join(metrics_dir, f'{model_paths[i].split(\"/\")[-2]}_stats.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCiKVxbf_x8y"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = '/home/pgajo/working/food/src/ner/spacy_outputs/output_bert-base-multilingual-cased_it_item-wise/model-best'\n",
        "# model_path = '/home/pgajo/working/food/src/ner/spacy_outputs/output_bert-base-multilingual-cased_it/model-best'\n",
        "ner_model = spacy.load(model_path)\n",
        "docs = list(test_bin.get_docs(ner_model.vocab))\n",
        "print('len(docs):', len(docs))\n",
        "print(docs[0].text)\n",
        "ner_model(docs[0].text)\n",
        "from spacy import displacy\n",
        "displacy.render(ner_model(docs[0].text), style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-VsLEqiljQU",
        "outputId": "250a7d4b-7863-4e9e-de6c-8dd127c311b9"
      },
      "outputs": [],
      "source": [
        "!pip install recipe-scrapers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9THhIHxmGhI",
        "outputId": "235cd389-0c7b-4291-a4ce-33b9b26df59d"
      },
      "outputs": [],
      "source": [
        "from recipe_scrapers import scrape_me\n",
        "\n",
        "# RECIPE_URL = \"https://ricette.giallozafferano.it/Trota-salmonata-in-crosta-di-pistacchi.html\"\n",
        "RECIPE_URL = \"https://cucchiaio.it/ricetta/torta-con-farina-di-mandorle/\"\n",
        "scraper = scrape_me(RECIPE_URL)\n",
        "scraper.ingredients()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsxu4HGxWBpQ"
      },
      "source": [
        "### Text Pre-Processing Function\n",
        "\n",
        "Note the float representations of ingredient quantities, in spite of the fact that the website shows them in mixed numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ES2pKiK0NOE"
      },
      "outputs": [],
      "source": [
        "from fractions import Fraction\n",
        "import re\n",
        "\n",
        "\n",
        "def fraction_to_mixed_number(fraction: Fraction) -> str:\n",
        "  if fraction.numerator >= fraction.denominator:\n",
        "    whole, remainder = divmod(fraction.numerator, fraction.denominator)\n",
        "    if remainder == 0:\n",
        "      return str(whole)\n",
        "    else:\n",
        "      return f\"{whole} {Fraction(remainder, fraction.denominator)}\"\n",
        "  else:\n",
        "    return str(fraction)\n",
        "\n",
        "\n",
        "def convert_floats_to_fractions(text: str) -> str:\n",
        "    return re.sub(\n",
        "        r'\\b-?\\d+\\.\\d+\\b',\n",
        "        lambda match: fraction_to_mixed_number(\n",
        "            Fraction(float(match.group())).limit_denominator()), text\n",
        "        )\n",
        "\n",
        "\n",
        "def process_text(text, model=nlp):\n",
        "  \"\"\"\n",
        "  A wrapper function to pre-process text and run it through our pipeline.\n",
        "  \"\"\"\n",
        "  return nlp(convert_floats_to_fractions(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1IbSIiFycKI",
        "outputId": "60fb0cff-4b40-4d7a-e6f1-719259aba42e"
      },
      "outputs": [],
      "source": [
        "# Let's have a look at our processing function at work\\\n",
        "fraction_mapping = { \n",
        "        '½': '1/2', '¼': '1/4', '¾': '3/4',\n",
        "        '⅓': '1/3', '⅔': '2/3', '⅕': '1/5',\n",
        "        '⅖': '2/5', '⅗': '3/5', '⅘': '4/5',\n",
        "        '⅙': '1/6', '⅚': '5/6', '⅛': '1/8',\n",
        "        '⅜': '3/8', '⅝': '5/8', '⅞': '7/8',\n",
        "    }\n",
        "import re\n",
        "def convert_single_char_fractions(text):\n",
        "    for key in fraction_mapping.keys():\n",
        "        text = text.replace(key, fraction_mapping[key])\n",
        "    return text\n",
        "\n",
        "[convert_single_char_fractions(convert_floats_to_fractions(line)) for line in scraper.ingredients()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6rbxA_fXPnE"
      },
      "source": [
        "### Running Inference with Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJHRbPaAXPBM"
      },
      "outputs": [],
      "source": [
        "# Load the model again for good measure\n",
        "nlp = spacy.load(f\"{output_path}/model-best/\")\n",
        "\n",
        "from spacy import displacy\n",
        "# process the recipe, line-by-line\n",
        "docs = [process_text(line, model = nlp) for line in scraper.ingredients()]\n",
        "\n",
        "displacy.render(docs, style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PREPPY_URL = 'https://preppykitchen.com/coffee-cake/'\n",
        "scraper = scrape_me(PREPPY_URL, wild_mode=True)\n",
        "scraper.ingredients()\n",
        "# process the recipe, line-by-line\n",
        "docs_preppy = [process_text(line) for line in scraper.ingredients()]\n",
        "\n",
        "displacy.render(docs_preppy, style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
